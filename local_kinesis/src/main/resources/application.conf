akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "INFO"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = 10
  log-dead-letters-during-shutdown = on
}

backoff {
  minbackoff-seconds = 3
  maxbackoff-seconds = 60
  random-factor = 0.2
}


inbound {
  rabbitmq {
    virtual-host = "/"
    username = "docker"
    password = "docker"
    addresses = ["rabbitmq:5672"]
    queue = "opfc_gamestate_consume"
    buffer-size = 10
  }
}

outbound {
  sink {
    parallel = 10
  }

  kafka {
    topic = "opfc_gamestate_topic"
    broker = "kafka:9092"
    bootstrap.servers = "kafka:9092"
    bootstrap.servers = ${?KAFKA}
    acks = "all"
    retries = 10
    retry.backoff.ms = 100
    # Tuning parameter of how many sends that can run in parallel.
    parallelism = 100

    # Duration to wait for `KafkaConsumer.close` to finish.
    close-timeout = 60s

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the producer stages. Some blocking may occur.
    # When this value is empty, the dispatcher configured for the stream
    # will be used.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
    # for exactly-once-semantics processing.
    eos-commit-interval = 100ms

    # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
    # can be defined in this configuration section.
    kafka-clients {
    }
  }
}
